{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "153dff2b-74b0-49f5-a927-0407065240f7",
   "metadata": {},
   "source": [
    "# Lesson 3: Model Deployement Workflow "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "135bbd10-2534-4a3e-98e7-0716bd834322",
   "metadata": {},
   "source": [
    "## Dataset Principles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe91b2ef-f4d6-422a-beb2-c13ad14bae7a",
   "metadata": {},
   "source": [
    "Your tasks for this exercise are:\n",
    "\n",
    "Create a dataframe with your features and target arrays from make_regression.\n",
    "Create a 60% Train / 20% Validation / 20% Test dataset group using the train_test_split method.\n",
    "Confirm the datasets are the correct size by outputing their shape.\n",
    "Save the three datasets to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2796d31-ee0f-4b46-ac3d-b08afd789d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f1f28c-e323-46ce-be0e-6f1139a67e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a regression dataset with 1000 samples, 5 feature columns, 2 which are actually useful, and 1 target column\n",
    "regression_dataset = make_regression(\n",
    "    n_samples=1000, n_features=5, n_informative=2, n_targets=1, random_state=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede00cc5-f72e-46e5-868c-6664eb857acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(regression_dataset[0])\n",
    "df[\"target\"] = regression_dataset[1]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53dd7989-e15a-422d-8780-26f2003f9476",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a train: 0.8 | test: 0.2 ratio dataset\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "\n",
    "# Create a train: 0.6 | validation: 0.2 ratio dataset\n",
    "df_train, df_val = train_test_split(df, test_size=0.25, random_state=0)\n",
    "# Final dataset sizes: train: 0.6, validation: 0.2, test: 0.2,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f863395-b03a-4bec-884d-08d2e5157794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output each shape to confirm the size of train/validation/test\n",
    "print(f\"Train: {df_train.shape}\")\n",
    "print(f\"Validation: {df_val.shape}\")\n",
    "print(f\"Test: {df_test.shape}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf5458c-517e-4406-ac6a-86078e07ace0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output all datasets to csv\n",
    "df_train.to_csv('train.csv', index=False)\n",
    "df_val.to_csv('validation.csv', index=False)\n",
    "df_test.to_csv('test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba82df84-9498-4990-af63-888b42e1766b",
   "metadata": {},
   "source": [
    "## Data Cleaning and Feature Engineering "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32199630-dc83-42cf-b92e-61239d1bee19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Creating a mixed dataset of strings, floats, and date strings\n",
    "df = pd.DataFrame(\n",
    "    [\n",
    "        [\"cat\", 1.0, \"3-2021\"],\n",
    "        [\"cat\", 0.5, \"1-2021\"],\n",
    "        [\"dog\", 0.2, \"5-2021\"],\n",
    "        [\"bird\", 3.3, \"3-2021\"],\n",
    "        [\"dog\", 5.7, \"1-2021\"],\n",
    "        [\"dog\", 0.0, \"2-2021\"],\n",
    "        [\"cat\", 1.9, \"4-2021\"],\n",
    "        [\"bird\", 2.4, \"4-2021\"],\n",
    "        [\"bird\", 2.4, \"5-2021\"]\n",
    "    ],\n",
    "    columns=[\"animal\", \"value\", \"date\"]\n",
    ")\n",
    "df.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0de190-0903-425b-9cf7-0c0a2022cf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change datatype \n",
    "df.loc[:, \"animal\"] = df[\"animal\"].astype(\"category\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb6dc1d-a2d6-453a-992a-7a7b153749a5",
   "metadata": {},
   "source": [
    "Normalizing Data\n",
    "Transforms numerical data to have specific range of values\n",
    "Transformations typically have zero mean, meaning their average is 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741f4853-8f61-48b6-ad20-7c603be68fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[[\"value\"]])\n",
    "scaler.transform(df[[\"value\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37556ccb-2712-4cc4-bd86-ddee24fa6879",
   "metadata": {},
   "source": [
    "Parsing Data Types\n",
    "Pandas to_datetime() method will parse datetime strings\n",
    "Converts strings to datetime objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369e5eee-8a54-45ef-8077-fbd1d9a2156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(df.loc[:, \"date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfed3fc-07a2-4b31-8174-8b3ccecbddf1",
   "metadata": {},
   "source": [
    "One-hot Encoding\n",
    "Required for models that only take numerical data\n",
    "Pandas has a one-hot encoding function,.get_dummies()\n",
    "Converts categorical data to many feature columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41739fe2-e1aa-4547-87f7-3bf82ff7b71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.get_dummies(df.animal, prefix=\"animal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a5ee6c-ba33-45da-8503-39f03fe01fda",
   "metadata": {},
   "source": [
    "## Exercise: Data Cleansing and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523b6700-4ebd-4fa2-b67d-2eaec9ce005a",
   "metadata": {},
   "source": [
    "Apply these changes to the data.csv dataset.\n",
    "\n",
    "Load data.csv into a dataframe.\n",
    "Output the table info to see if there are any null values.\n",
    "Remove all null values from the dataframe.\n",
    "Change the date column from an object to a datetime64[ns] type.\n",
    "Change the weather column to a category type.\n",
    "One hot encode the date column to year, month, and day.\n",
    "Normalized the columns from the all_features list so each feature has a zero mean.\n",
    "Create and save the cleaned dataframe, as well as the train/validation/test dataframes to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8e1798-f4fa-40d9-a344-c0a7d1fcf377",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ed44876-0059-4078-806d-3fd42e6b191f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset created by 02_exercise_dataset_creation.ipynb\n",
    "df = pd.read_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70fbb8f-c1df-4d2a-aa5b-90160a08c09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output general info about the table, notice we have some null values in all of our features\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2847fa88-6407-482d-91d8-d242437eee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fb044b-c578-42a0-91d5-c2c2b8271937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all null values\n",
    "df.dropna().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df0c2b1-bcab-461b-8d03-f93d304ee22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the date column to a datetime\n",
    "df.loc[:, 'date'] = pd.to_datetime(df.loc[:, 'date'])\n",
    "# Change weather column to a category\n",
    "df.loc[:, 'weather'] = df[\"weather\"].astype(\"category\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "771c4c05-f6cf-4ccb-b61d-5e5b2b2b7360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year, month, and day into separate columns\n",
    "df['year'] = df.date.dt.year\n",
    "df['month'] = df.date.dt.month\n",
    "df['day'] = df.date.dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152852c9-8079-4917-bebb-7b0c5250a48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode the weather category to have individual features. Prefix with `weather`\n",
    "weather_one_hot_df = pd.get_dummies(df.weather, prefix='weather')\n",
    "weather_one_hot_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6ffa80-6e55-4723-985e-06370913bf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the one hot encoded values back to the df\n",
    "df[weather_one_hot_df.columns.tolist()] = weather_one_hot_df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192a8f62-36ce-4c34-9cf7-d7eb71c42335",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify now that are table info has no nulls and correct Dtypes\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baaea42b-7345-41d5-8325-b204a0cfc805",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mpute the data with any of the two lines below:\n",
    "data = data.fillna(lambda x: x.median()) #or\n",
    "data = data.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2be769a4-7782-4969-8489-914173c9b682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# These may change if you decided to call your columns different from above\n",
    "all_features = [\n",
    "    \"feature0\",\n",
    "    \"feature1\",\n",
    "    \"feature2\",\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"day\",\n",
    "    \"weather_cloudy\",\n",
    "    \"weather_rainy\",\n",
    "    \"weather_sunny\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc1ac78-3b96-4755-9cd5-b38e092010fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Table summary, notice the mean to many of our tables are not zero.\n",
    "df[all_features].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e522b7-d28d-487f-aa7c-7cad61d7b530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standarize feature values to have a zero mean\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df[all_features])\n",
    "df.loc[:, all_features] = scaler.transform(df[[all_features]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92075c2b-294c-4daa-a9de-2a54958a6a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train: 0.8 | test: 0.2\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "\n",
    "# train: 0.6 | validation: 0.2\n",
    "df_train, df_val = train_test_split(df_train, test_size=0.25, random_state=0)\n",
    "\n",
    "# Final dataset sizes: train: 0.6, validation: 0.2, text: 0.2,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c144236d-f241-49a6-80e9-807ab618b5d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output each shape to confirm the size of train/validation/test\n",
    "print(f\"Train: {df_train.shape}\")\n",
    "print(f\"Validation: {df_val.shape}\")\n",
    "print(f\"Test: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30d004cc-01b0-41df-8b3c-7a995af34056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all clean data, and the train, validation, test data as csv\n",
    "df.to_csv(\"data_clean.csv\", index=False)\n",
    "df_train.to_csv(\"train.csv\", index=False)\n",
    "df_val.to_csv(\"validation.csv\", index=False)\n",
    "df_test.to_csv(\"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "918900a9-6965-4368-a6d0-fbecf63729eb",
   "metadata": {},
   "source": [
    "## Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df4a114-fb49-4e27-8e3b-1d722d62f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = pd.DataFrame([[5, 3.4, 6], [1, 0.4, 10], [2, 0.1, 1]])\n",
    "target = [0, 1, 1]\n",
    "\n",
    "# One line model creation\n",
    "reg = LinearRegression().fit(df, target)\n",
    "\n",
    "# Score model with default metrics\n",
    "print(reg.score(df, target))\n",
    "\n",
    "#output\n",
    "1.0\n",
    "\n",
    "# Predict targets\n",
    "print(reg.predict(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681a85e7-4978-449b-9c6d-59a9f3b5e231",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/modules/neighbors.html guide to all models\n",
    "https://towardsdatascience.com/20-popular-machine-learning-metrics-part-1-classification-regression-evaluation-metrics-1ca3e282a2ce  Model evaluation\n",
    "https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics  scikit-learn API Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153a2613-9c44-4853-9cdf-55a2473bd72e",
   "metadata": {},
   "source": [
    "## Exercise: Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4165fd5-1db2-43d2-a77e-5a437a30355f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87dddf48-2542-4bf9-b66a-ff44d98aaa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_dataset = make_regression(\n",
    "    n_samples=10000,\n",
    "    n_features=10,\n",
    "    n_informative=5,\n",
    "    bias=0,\n",
    "    noise=40,\n",
    "    n_targets=1,\n",
    "    random_state=0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e315f3f-69ec-4a17-b232-e3618522b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataframe using the dataset\n",
    "df = pd.DataFrame(regression_dataset[0])\n",
    "df[\"target\"] = regression_dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a96d34-c56a-4f19-96f2-b173a4b10afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train: 0.8 | test: 0.2\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "\n",
    "# train: 0.6 | validation: 0.2\n",
    "df_train, df_val = train_test_split(df, test_size=0.25, random_state=0)\n",
    "\n",
    "# Final dataset sizes: train: 0.6, validation: 0.2, text: 0.2,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297d79c4-1507-4490-a18f-b435b0ee4add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output each shape to confirm the size of train/validation/test\n",
    "print(f\"Train: {df_train.shape}\")\n",
    "print(f\"Validation: {df_val.shape}\")\n",
    "print(f\"Test: {df_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33937db-a98c-4187-afcf-7b54e95a8a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the linear model by fitting it on the dataframe features and dataframe target\n",
    "reg = LinearRegression().fit(df_train[list(range(10))], df_train['target'])()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c60c4aec-f3e5-412e-a9e8-9e8d7425a8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the linear model by scoring it, by default it's the metric r2.\n",
    "reg.score(df_val[list(range(10))], df_val['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c978923b-9d0b-4a51-b3a1-b72b33485026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once done optimizing the model using the validation dataset,\n",
    "# Evaluate the linear model by scoring it on the test dataset.\n",
    "reg.score(df_test[list(range(10))], df_test['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6773a960-9dc2-44a0-a94a-daad58880e18",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824f62b-1176-46ec-b30d-43a92ea56c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# create baseline with default params\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# create model with hyperparameters\n",
    "model = DecisionTreeClassifier(\n",
    "    max_depth=10,\n",
    "    criterion=\"entropy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955272cd-f70f-42c0-bd62-24823b2ae16e",
   "metadata": {},
   "source": [
    "Hyperparameter sources\n",
    "https://scikit-learn.org/stable/modules/classes.html#hyper-parameter-optimizers \n",
    "https://scikit-learn.org/stable/modules/grid_search.html\n",
    "https://neptune.ai/blog/hyperparameter-tuning-in-python-complete-guide"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdc950f-efc1-4c25-ae11-c7b7cc807eba",
   "metadata": {},
   "source": [
    "## Exercise: Diabetes Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dedc55e-af77-4709-98cd-ea366b9346b0",
   "metadata": {},
   "source": [
    "Load the diabetes dataset into a dataframe.\n",
    "Check the table summary to show that indeed the mean is zero for all features.\n",
    "Split the dataset into train, validation, and test sets\n",
    "Use a linear regression Ridge model to fit and score:\n",
    "Fit and score on the whole dataset\n",
    "Fit on train, score on validation, using default model\n",
    "Fit on train, score on validation, using hyperparameters model\n",
    "Fit on train, score on test, using hyperparameterized model\n",
    "Plot all scores in a bar graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a4d8d8-d304-4c39-8680-fb08459c5627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c32f28c-ab44-4ae0-916e-b22395fdddb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b293872b-3cd0-43d8-86d8-254e2f44fc2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381e5ee-db6d-4e3c-b665-71eed7f81e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the diabetes `data` dataset as a dataframe and name the columns with `feature_names`\n",
    "df = pd.DataFrame(diabetes['data'], columns=diabetes['feature_names'])\n",
    "\n",
    "# Include the target as well\n",
    "df['target'] = diabetes['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c86c63-9bc2-4923-97d6-5f3aede973b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe df using table summary.\n",
    "# No need to normalize, near zero mean.\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd2e1d1d-e487-4f4b-bde7-bbd6b64760b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36ccb3c-0cbe-4e66-9d45-e72c741ae0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train: 0.8 | test: 0.2\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "\n",
    "# train: 0.6 | validation: 0.2\n",
    "df_train, df_val = train_test_split(df, test_size=0.25, random_state=0)\n",
    "\n",
    "# Final dataset sizes: train: 0.6, validation: 0.2, text: 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f0b35db-36cc-4acb-98eb-481a00f93c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the model perform on the entire dataset and default model parameters\n",
    "reg = Ridge().fit(df[diabetes['feature_names']], df['target'])\n",
    "all_df_score = reg.score(df[diabetes['feature_names']], df['target'])\n",
    "all_df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c167833-1a1c-4ce7-91d4-cd6a37963b78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the model perform on the training dataset and default model parameters\n",
    "# Remember we use the validation dataset score the model\n",
    "reg = Ridge().fit(df_train[diabetes['feature_names']], df_train['target'])\n",
    "val_df_score = reg.score(df_val[diabetes['feature_names']], df_val['target'])\n",
    "val_df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad59d14-7dab-40e4-8839-28540b1a23ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the model perform on the training dataset and different model parameters\n",
    "# Change alpha, solver, and max_iter\n",
    "reg_h = Ridge(alpha=0.01, solver=\"saga\", max_iter=10000).fit(df_train[diabetes['feature_names']], df_train['target'])\n",
    "val_df_h_score = reg_h.score(df_val[diabetes['feature_names']], df_val['target'])\n",
    "val_df_h_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabdce82-7816-4fcb-b80c-2b9f06aee2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use optimized model on the held out test dataset.\n",
    "test_df_h_score = reg_h.score(df_test[diabetes[\"feature_names\"]], df_test[\"target\"])\n",
    "test_df_h_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99433f5f-ac17-4685-8f5b-8f20a6835e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bar plot of all scores from each model fit: all_df_score, val_df_score, val_df_h_score, test_df_h_score\n",
    "import matplotlib as plt \n",
    "\n",
    "pd.Series({\"all_df_score\": all_df_score,\n",
    "        \"val_df_score\": val_df_score,\n",
    "        \"val_df_h_score\": val_df_h_score,\n",
    "        \"test_df_h_score\": test_df_h_score,}).plot(kind=\"bar\", legend=False, title=\"R2 Score of Ridge Model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cca0ec-b903-46fd-b320-aa31506faf11",
   "metadata": {},
   "source": [
    "## Lesson 4: Algorithms and Tools "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5431232b-f2b4-4abc-a01d-e07b89797844",
   "metadata": {},
   "source": [
    "Linear models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9103b3f-9e41-4957-a7b5-ed23fee7272f",
   "metadata": {},
   "source": [
    "addtional resources "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88529143-893d-45b7-a8ea-ce1be02ddad8",
   "metadata": {},
   "source": [
    "https://docs.aws.amazon.com/sagemaker/latest/dg/linear-learner.html\n",
    "\n",
    "https://scikit-learn.org/stable/modules/linear_model.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff832e17-08b5-4311-9c5d-1f0dcf6e5dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code Example of Linear Model\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [[1, 2, 0], [3, 4, 1], [5, 6, 0], [7, 8, 1]],\n",
    "    columns=[\"num\", \"amount\", \"target\"]\n",
    ")\n",
    "\n",
    "# regression model\n",
    "reg = LinearRegression().fit(df[[\"num\", \"amount\"]], df[\"target\"])\n",
    "reg.score(df[[\"num\", \"amount\"]], df[\"target\"])\n",
    "\n",
    "#classification model\n",
    "clf = LogisticRegression().fit(df[[\"num\", \"amount\"]], df[\"target\"])\n",
    "clf.score(df[[\"num\", \"amount\"]], df[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3662a8fb-adde-478f-bd59-41b151af8a3c",
   "metadata": {},
   "source": [
    "## Exercise: Linear Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c66be0e-be2a-48e9-99ea-b34f4536628e",
   "metadata": {},
   "source": [
    "You're tasked with compeleting the following steps:\n",
    "\n",
    "Load in the wine dataset from scikit learn.\n",
    "For the wine dataset, create a train and test split, 80% train / 20% test.\n",
    "Create a LogisticRegression model with these hyper parameters: random_state=0, max_iter=10000\n",
    "Evaluate the model with the test dataset\n",
    "Load the diabetes dataset from scikit learn\n",
    "For the Diabetes dataset, create a train and test split, 80% train / 20% test.\n",
    "Create a SGDRegressor model model with these hyper parameters: random_state=0, max_iter=10000\n",
    "Evaluate the model with the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119b3b57-0028-45f6-8e09-5c1b1d722528",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, SGDRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9ae2b9a-59b8-4c6b-a72d-9a487fc2f40a",
   "metadata": {},
   "source": [
    "Linear Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd83dc1b-813b-4079-b69b-9613f64e0b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the wine dataset\n",
    "wine = datasets.load_wine()\n",
    "wine.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e263811-fee6-4552-a9dd-d3bdb63095a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the wine `data` dataset as a dataframe and name the columns with `feature_names`\n",
    "df = pd.DataFrame(wine['data'], columns=wine['feature_names'])\n",
    "\n",
    "# Include the target as well\n",
    "df['target'] = wine['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c972fae-c81c-4216-b619-10d9e614e368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split your data with these ratios: train: 0.8 | test: 0.2\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adc6232-3d73-4d0d-a415-09e9674140a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the model perform on the training dataset and default model parameters?\n",
    "# Using the hyperparameters in the requirements, is there improvement?\n",
    "# Remember we use the test dataset to score the model\n",
    "clf = LogisticRegression(random_state=0, max_iter=10000).fit(df_train[wine['feature_names']], df_train['target'])\n",
    "clf.score(df_test[wine[\"feature_names\"]], df_test[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eee452a-664e-485b-aeb6-f12f4e30a409",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404e57a4-87c2-4793-8848-a7741906c388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f713067-d3b8-466e-b752-9cf6bb2175e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the model perform on the training dataset and default model parameters?\n",
    "# Using the hyperparameters in the requirements, is there improvement?\n",
    "# Remember we use the test dataset to score the model\n",
    "reg = SGDRegressor(random_state=0, max_iter=10000).fit(dfd_train[diabetes['feature_names']], dfd_train['target'])\n",
    "reg.score(dfd_test[diabetes[\"feature_names\"]], dfd_test[\"target\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab16b21-5175-4942-939a-8165ce714541",
   "metadata": {},
   "source": [
    "## Tree Based Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7fd0ad-e55e-422b-9def-f2057165e3a3",
   "metadata": {},
   "source": [
    "decision tree   https://scikit-learn.org/stable/modules/tree.html#tree\n",
    "random forest    https://scikit-learn.org/stable/modules/ensemble.html#forests-of-randomized-trees\n",
    "hierarchical     https://en.wikipedia.org/wiki/Hierarchical_clustering\n",
    "feature selection  https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e368e96-3e1e-49a7-bcbc-dda3a69089fe",
   "metadata": {},
   "source": [
    "## XGBoost Model: Tree based model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e580e9-c157-46bf-a5ba-bff2918bb083",
   "metadata": {},
   "source": [
    "XGBoost is a tree-based model with a different implementation compared to other tree-based models. The ensemble it creates is comprised of weak learners, meaning that each tree in the ensemble can barely make accurate predictions. But with enough of these models, it actually creates an ensemble that usually outperforms random forests. A benefit to XGBoost is that it provides a way to highly optimize the models. This is done by offering a large number of hyperparameters to tune. The downside to all these optimizations, and with ensemble models in general, is that they are hard to interpret."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c21258aa-273f-4693-91f7-5a8d393bfcfa",
   "metadata": {},
   "source": [
    "https://xgboost.readthedocs.io/en/latest/prediction.html\n",
    "\n",
    "https://arxiv.org/abs/1603.02754"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb93977-d926-486f-8dc4-a4409e5832d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code Example of XGBoost\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [[1, 2, 0], [3, 4, 1], [5, 6, 0], [7, 8, 1]],\n",
    "    columns=[\"num\", \"amount\", \"target\"]\n",
    ")\n",
    "df_xgb = xgb.DMatrix(\n",
    "    df[[\"num\", \"amount\"]], label=df[\"target\"]\n",
    ")\n",
    "params = {\"eval_metric\": \"logloss\", \"objective\": \"binary:hinge\"}\n",
    "bst = xgb.train(params, df_xgb)\n",
    "\n",
    "bst.predict(df_xgb)\n",
    "\n",
    "# output\n",
    "array([0., 1., 0., 1.], dtype=float32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333891cc-7677-4418-be9c-71e8dfdf0bcf",
   "metadata": {},
   "source": [
    "Exercise: XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e703e44-557a-4a2c-a340-ff2afba59dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the wine dataset\n",
    "wine = datasets.load_wine()\n",
    "\n",
    "# Create the wine `data` dataset as a dataframe and name the columns with `feature_names`\n",
    "df = pd.DataFrame(wine['data'], columns=wine['feature_names'])\n",
    "\n",
    "# Include the target as well\n",
    "df['target'] = wine['target']\n",
    "\n",
    "# Split your data with these ratios: train: 0.8 | test: 0.2\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)\n",
    "\n",
    "# Load your train/test dataframe into DMatrix\n",
    "dtrain = xgb.DMatrix(df_train[wine['feature_names']], df_train['target'])\n",
    "dtest = xgb.DMatrix(df_test[wine['feature_names']], df_test['target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8392f2b-dbe6-465b-8bb7-02883159f568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the model perform on the training dataset and default model parameters?\n",
    "# Using the hyperparameters in the requirements, is there improvement?\n",
    "# Remember we use the test dataset to score the model\n",
    "params = param = {\"max_depth\": 10, \"eta\": 1, \"objective\": \"multi:softmax\", \"num_class\": 5}\n",
    "num_round = 100\n",
    "\n",
    "bst = xgb.train(params, dtrain, num_round)\n",
    "\n",
    "\n",
    "# xgboost is not scikit learn, so you'll need to do predictions using their API\n",
    "preds = bst.predict(dtest)\n",
    "\n",
    "# Accuracy score using scikit learn function for classification metric\n",
    "accuracy_score(df_test['target'], preds)\n",
    "\n",
    "\n",
    "# Plot the importance of the features based on fitted trees\n",
    "xgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead7b7da-5a37-40b8-a82e-5768237d0c83",
   "metadata": {},
   "source": [
    "XGBoost Regression Ex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc9f74f8-949f-4d84-8c4e-1c443bfe0fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the diabetes dataset\n",
    "diabetes = diabetes = datasets.load_diabetes()\n",
    "\n",
    "# Create the diabetes `data` dataset as a dataframe and name the columns with `feature_names`\n",
    "dfd = pd.DataFrame(diabetes['data'], columns=diabetes['feature_names'])\n",
    "\n",
    "# Include the target as well\n",
    "dfd['target'] = diabetes['target']\n",
    "\n",
    "# Split your data with these ratios: train: 0.8 | test: 0.2\n",
    "dfd_train, dfd_test = train_test_split(dfd, test_size=0.2, random_state=0)\n",
    "\n",
    "# Load your train/test dataframe into DMatrix\n",
    "dtrain = xgb.DMatrix(dfd_train[diabetes['feature_names']], dfd_train['target'])\n",
    "dtest = xgb.DMatrix(dfd_test[diabetes['feature_names']], dfd_test['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56502b6b-9eab-41df-a737-fad08a19a93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the model perform on the training dataset and default model parameters?\n",
    "# Using the hyperparameters in the requirements, is there improvement?\n",
    "# Remember we use the test dataset to score the model\n",
    "param = { \"max_depth\": 2, \"eta\": 0.03, \"gamma\": 0.09, \"colsample_bytree\": 0.5,  \"objective\": \"reg:squarederror\",}\n",
    "\n",
    "num_round = 100\n",
    "\n",
    "bst = xgb.train(param, dtrain, num_round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e62293-5d95-4897-8682-76559b2c62fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgboost is not scikit learn, so you'll need to do predictions using their API\n",
    "preds = bst.predict(dtest)\n",
    "\n",
    "# R2 score using scikit learn function for regression metric\n",
    "r2_score(dfd_test['target'], preds)\n",
    "\n",
    "# Plot the importance of the features based on fitted trees\n",
    "xgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668e000d-b2b0-47d3-9c2f-de6ddf597569",
   "metadata": {},
   "source": [
    "## AutoGluon Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d311d7-3899-4a82-92c0-db0cb7b2451d",
   "metadata": {},
   "source": [
    "AutoGluon is a framework that automates the processing, creating, and tuning of ML models. It is part of a class of models call AutoML, which automates the machine learning workflow. In AutoGluon, the main parameters you use are: defining the target value for a dataset, and how long to train for. It will automate everything else, trying a variety of models and parameters up to the time limit. Because of its ease of use, it is a new way to easily create a baseline model. Another benefit of AutoGluon is the way it tries so many different models. Providing metrics on all of the models, you can see how different models work on your data that would otherwise not be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33babec2-8e35-4716-8129-a76811c7424f",
   "metadata": {},
   "source": [
    "https://auto.gluon.ai/stable/index.html\n",
    "\n",
    "https://en.wikipedia.org/wiki/Automated_machine_learning\n",
    "\n",
    "https://github.com/windmaple/awesome-AutoML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79a192d-bf10-451a-bbe6-a66e95efb312",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Code Example of AutoGluon\n",
    "\n",
    "import pandas as pd\n",
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    [[1, 2, 0], [3, 4, 1], [5, 6, 0], [7, 8, 1]],\n",
    "    columns=[\"num\", \"amount\", \"target\"]\n",
    ")\n",
    "\n",
    "predictor = TabularPredictor(label=\"target\").fit(\n",
    "    train_data=df,\n",
    "    time_limit=60,\n",
    "    presets=\"best_quality\"\n",
    ")\n",
    "\n",
    "# output a summary of created models\n",
    "predictor.fit_summary()\n",
    "\n",
    "# evaluate best model from hyperparameter search\n",
    "performance = predictor.evaluate(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef010a8-672f-4cbf-a7fa-8f249096fd11",
   "metadata": {},
   "source": [
    "Exercise: AutoGluon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bd56c9-cdbd-41e4-8b64-eccd0619ccf8",
   "metadata": {},
   "source": [
    "Load in the wine dataset from scikit learn.\n",
    "For the wine dataset, create a train and test split, 80% train / 20% test.\n",
    "Create a AutoGluon Classifier model with these hyper parameters:\n",
    "\n",
    "time_limit: 120\n",
    "presets: best_quality\n",
    "Output the model table summary\n",
    "\n",
    "Evaluate the trained model on the test dataset\n",
    "Load the diabetes dataset from scikit learn\n",
    "For the Diabetes dataset, create a train and test split, 80% train / 20% test.\n",
    "Create a AutoGluon Regression model with these hyper parameters:\n",
    "\n",
    "eval_metric: r2\n",
    "time_limit: 120\n",
    "presets: best_quality\n",
    "Output the model table summary\n",
    "\n",
    "Evaluate the trained model on the test dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481ebbf0-bdfc-4ca7-abba-c79cefbb26e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -U pip\n",
    "!pip install -U setuptools wheel\n",
    "!pip install -U \"mxnet<2.0.0\" bokeh==2.0.1\n",
    "!pip install autogluon --no-cache-dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14491d48-9355-4aac-a9b8-cea2f07ec4a8",
   "metadata": {},
   "source": [
    "Setup\n",
    "Open up Sagemaker Studio\n",
    "Notebook should be using a ml.t3.medium instance (2 vCPU + 4 GiB)\n",
    "Notebook should be using kernal: Python 3 (MXNet 1.8 Python 3.7 CPU Optimized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9c6091-7474-48ae-a424-0f47b7e7ffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from autogluon.tabular import TabularDataset, TabularPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dc4d74-deab-44c3-afee-32d6967b4d49",
   "metadata": {},
   "source": [
    "AutoGluon Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf8f560-12db-4dd3-84b2-9b891a3580ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the wine dataset\n",
    "wine = datasets.load_wine()\n",
    "\n",
    "# Create the wine `data` dataset as a dataframe and name the columns with `feature_names`\n",
    "df = pd.DataFrame(wine['data'], columns=wine['feature_names'])\n",
    "\n",
    "# Include the target as well\n",
    "df['target'] = wine['target']\n",
    "\n",
    "# Split your data with these ratios: train: 0.8 | test: 0.2\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "358c10c7-47d4-4dea-92a8-9b324f9628e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the model perform on the training dataset and default model parameters?\n",
    "# Using the hyperparameters in the requirements, is there improvement?\n",
    "# Remember we use the test dataset to score the model\n",
    "# No need to explicitly say this is a classifier, autogluon will pick it up\n",
    "predictor = TabularPredictor(label ='target').fit(train_data=df_train, time_limit=120,\n",
    "                                                  presets=\"best_quality\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ecd9e7-cb2e-4356-b128-7a8923e0cf2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models performance on the test dataset\n",
    "performance = performance = predictor.evaluate(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e797c790-0ac8-4486-b215-3535db13c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the model's `score_val` in a bar chart to compare performance\n",
    "predictor.leaderboard(silent=True).plot(kind=\"bar\", x=\"model\", y=\"score_val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4082f40-4d48-4b9c-931a-2925902173eb",
   "metadata": {},
   "source": [
    "AutoGluon Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc2b1c8-a5f2-4147-94f6-327671770b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the diabetes dataset\n",
    "diabetes = datasets.load_diabetes()\n",
    "\n",
    "# Create the diabetes `data` dataset as a dataframe and name the columns with `feature_names`\n",
    "dfd = pd.DataFrame(diabetes[\"data\"], columns=diabetes[\"feature_names\"])\n",
    "\n",
    "# Include the target as well\n",
    "dfd['target'] = diabetes[\"target\"]\n",
    "\n",
    "# Split your data with these ratios: train: 0.8 | test: 0.2\n",
    "dfd_train, dfd_test = train_test_split(dfd, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090a3b3-5f2f-4860-a610-a1763c3b5bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does the model perform on the training dataset and default model parameters?\n",
    "# Using the hyperparameters in the requirements, is there improvement?\n",
    "# Remember we use the test dataset to score the model\n",
    "# No need to explicitly say this is a regression, autogluon will pick it up\n",
    "predictor = TabularPredictor(label=\"target\", problem_type=\"regression\", eval_metric=\"r2\"\n",
    "                            ).fit(train_data=dfd_train, time_limit=120, presets=\"best_quality\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba7fdbb-09a4-422f-a0ec-555eba190be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the fit summary of the training run\n",
    "predictor.fit_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681a18da-4933-46a0-95f0-8dc842ce64fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the models performance on the test dataset\n",
    "performance = predictor.evaluate(dfd_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6176d89e-0486-495c-bca9-a1c8592c22ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the model's `score_val` in a bar chart to compare performance\n",
    "predictor.leaderboard(silent=True).plot(kind=\"bar\", x=\"model\", y=\"score_val\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4fddbf-a7cd-46b9-818c-fad89a782957",
   "metadata": {},
   "source": [
    "Sagemaker Jumpstart : https://docs.aws.amazon.com/sagemaker/latest/dg/studio-jumpstart.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "877f9b0e-debb-4736-8979-0405365d0d69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
