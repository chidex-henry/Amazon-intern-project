{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2384f613-ca73-4ec0-a8d8-d87acc1d3b21",
   "metadata": {},
   "source": [
    "## Lambda demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5e1b63-6bb4-4d8c-acfa-3b02cbf7662b",
   "metadata": {},
   "source": [
    "Invoking Lambda in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae28a9f-3010-4815-b9c6-54d9bb715b52",
   "metadata": {},
   "source": [
    "Lambda functions can be developed in Python through a Python package called Boto3. Boto3 is the AWS SDK to interact and manage AWS services, including Lambda. You do so through a client:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd809f09-2f45-4df7-89fe-2d31a52b24d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "client = boto3.client('lambda')\n",
    "\n",
    "# Code is uploaded in boto3 to lambda through the function create_function.\n",
    "\n",
    "response = client.create_function(\n",
    "    FunctionName='botoLambdaFunction1',\n",
    "    Role='arn:aws:iam::565094796913:role/lambda_full_access',\n",
    "    Code={ 'ZipFile': code})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a40877a5-6842-455d-9af0-e405d1ab7eca",
   "metadata": {},
   "source": [
    "lambda Console \n",
    "\n",
    "\n",
    "From the Lambda console, we'll select Create new function. We'll then create an author-from-scratch function that has a runtime environment of Python 3.\n",
    "\n",
    "We'll then create a test event to see if this function actually works. We’ll click test and then click configure test event. We'll leave the default 'hello-world' event. If we click test, we can see the specified status code and we can also see the specified body in the execution.\n",
    "\n",
    "What if an error occurred outside a test environment, and we wanted to see what the issue was? Click monitor, then view logs in CloudWatch. We can see logs right here, and clicking through we may be able to see the source of the error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1442dc5f-c9b1-4ddb-bb49-70fd3f267bfc",
   "metadata": {},
   "source": [
    "Lambda SDK\n",
    "\n",
    "In the SDK, we can create a function through boto3. We first need to write this lambda function to our local machine. Then, we’ll create a boto3 session for Lambda, and pass in the binary code of our zipped up code into the create-function method. A few reminders:\n",
    "\n",
    "By default, SageMaker execution roles won’t have access to Lambda, you’ll need to add this permission through the IAM console.\n",
    "You’ll need to create an execution role for the Lambda function. Again, you’ll need to do this through the IAM console.\n",
    "Names for Lambda functions need to be unique. Finally, you’ll need to pass in the right lambda handler name. (lambda_function.lambda_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83de0278-2b5e-405f-b526-eb6cdc7fac2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "from sagemaker import get_execution_role\n",
    "from zipfile import ZipFile\n",
    "role = get_execution_role()\n",
    "client = boto3.client('lambda')\n",
    "\n",
    "with ZipFile('code.zip', 'w') as f:\n",
    "    f.write('lambda_function.py')\n",
    "\n",
    "# If submitting as a ZipFile, you need to insert raw data. \n",
    "with open('code.zip', 'rb') as f:\n",
    "    b_code = f.read()\n",
    "\n",
    "response = client.create_function(\n",
    "    FunctionName='botoLambdaFunction1',\n",
    "    Runtime='python3.9',\n",
    "    Handler='lambda_function.lambda_handler',\n",
    "    Code={\n",
    "        'ZipFile': b_code\n",
    "    },\n",
    "    Description='string',\n",
    "    Timeout=30,\n",
    "    MemorySize=1024,\n",
    "    Publish=True,\n",
    "    PackageType='Zip',\n",
    "    Role='arn:aws:iam::565094796913:role/lambda_full_access'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee33fb1a-cfeb-4e78-a5e3-07e819c8d33c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75aad10f-9de8-4851-b71f-0367015c58e4",
   "metadata": {},
   "source": [
    "## Triggering a Lambda Function Demo\n",
    "\n",
    "In this demo, we demonstrate how to trigger a Lamda in the following two ways:\n",
    "\n",
    "CloudWatch Scheduled Event\n",
    "\n",
    "SDK\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c5f867-7d00-40fe-9c96-63cbddc82498",
   "metadata": {},
   "source": [
    "### through CloudWatch Scheduled Event\n",
    "\n",
    "CloudWatch Scheduled Events\n",
    "\n",
    "We'll start with CloudWatch Scheduled Events. We have two options under \"rules\".\n",
    "\n",
    "\"Event Pattern\" would be what we use if we wanted to send an event based on an API call appearing somewhere.\n",
    "\n",
    "\"Schedule\" is how we can specify a Scheduled Event. There, we can specify an interval and a target. Once done, we need to wait for an interval of the length we specified to elapse before we see any invocations.\n",
    "\n",
    "If we click through to the lambda function, there are two visual cues that indicate what we've done.\n",
    "\n",
    "We can see invocations under \"monitor\".\n",
    "\n",
    "We can see in the \"overview\" that CloudWatch events were added as a trigger."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe7479c-facc-4780-93e6-69c4419942a6",
   "metadata": {},
   "source": [
    "SDK\n",
    "\n",
    "We'll then trigger a Lambda function in Python through Boto3. Here, similar to how AWS Services can send an event to Lambda, we too can draft an event that we can send to Lambda. The steps to do this are...\n",
    "\n",
    "Spin up a boto3 Lambda client.\n",
    "\n",
    "Ensure your execution role needs to have access to Lambda.\n",
    "\n",
    "From there, you can specify the payload as a JSON-serializable object.\n",
    "\n",
    "Convert it into a byte array.\n",
    "\n",
    "Call the invoke method.\n",
    "\n",
    "You can verify that the invocation was successful through the response object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45a0b020-8119-4d9d-b4c7-d37c536a9fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SDK\n",
    "\n",
    "import boto3\n",
    "from sagemaker import get_execution_role \n",
    "## The SageMaker role executing your notebook needs to have Lambda permissions. \n",
    "import json\n",
    "\n",
    "client = boto3.client('lambda')\n",
    "\n",
    "payload = {'key': 'value'}\n",
    "\n",
    "payload_bytes = json.dumps(payload).encode('utf-8')\n",
    "\n",
    "response = client.invoke(\n",
    "    FunctionName='example123',\n",
    "    InvocationType='Event',\n",
    "    Payload=payload_bytes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0825e72-696b-4b23-95ec-914eca678dbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9191663c-0e83-4b34-8e92-6649032b9a49",
   "metadata": {},
   "source": [
    "UDACITY : Designing Your First Workflow - Invoking Lambda Functions\n",
    "\n",
    "In the last exercise, you created your own Lambda function. Without realizing it, you've already practiced invoking as well! Launching a test event is an example of synchronous invocation. In this exercise, you will continue working on the lambda function 'PreprocessLambda' from the previous exercise. However, you'll practice a different way to launch asynchronous invocation, and also practice the setup of an asynchronous invocation. These are only two examples. Lambda is one of the most flexible offerings in AWS and can be utilized in a variety of applications. The same Lambda function can be (and often is) both invoked synchronously and asynchronously.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d3bf6f2-32a2-430b-ad14-7040b147dbdd",
   "metadata": {},
   "source": [
    "## Exercise: Synchronous invocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd26bc6f-5022-4ea9-a474-b03b32336895",
   "metadata": {},
   "source": [
    "Synchronous invocations occur when a call is made to a Lambda function and a response is waited for. The example we're asking you to implement is a CLI invocation, but Lambda functions can also be placed behind Amazon's API Gateway for potential users to directly invoke a Lambda function. This, in turn, could be the interface that you expose to users to allow them to interact with other AWS resources. These types of invocations are great for \"get\" and \"set\" methods.\n",
    "\n",
    "Your task is to synchronously invoke the Lambda function you implemented in the last exercise using the CLI. The following documentation may be useful to you: https://docs.aws.amazon.com/lambda/latest/dg/invocation-sync.html\n",
    "\n",
    "You will need to attach the LambdaFullAccess policy to the SageMaker execution role used for your notebook. Once done, it will take a few minutes for the policy to register."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf43491-34b4-4382-8898-337fb1f9a218",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "# echo \"Example CLI Command.\"\n",
    "aws lambda invoke --function-name preprocess-helloblze --payload '{\"s3-dataset-uri\": \"s3://mldeployex/trigger-demo/reviews_Patio_Lawn_and_Garden_5.json.zip\"}' response.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ad5a8a6-4162-4abb-9e75-110dd40639ba",
   "metadata": {},
   "source": [
    "## Exercise: Asynchronous invocation\n",
    "\n",
    "Asynchronous invocations occur when a service invokes lambda but does not wait for a response. The two most popular services that utilize asynchronous invocations are S3 (the storage we've been using) and SNS (Simple Notification Service.) We'll be setting up asynchronous invocations on an S3 bucket for our preprocessing function.\n",
    "\n",
    "Your task is to setup a trigger for the Lambda function we've been working whenever a file is uploaded to a specific folder in S3. You will need to do the following:\n",
    "\n",
    "Create a new s3 folder within an existing bucket.\n",
    "Create a new lambda trigger for S3 by clicking '+Add trigger'. Specifying the bucket. Specify a prefix of the desired folder. Specify a suffix of \".zip\" to ensure that recursive calls don't occur.\n",
    "Modify the lambda handler in the previous exercise using the starter code so that it properly parses the event that's sent to it.\n",
    "To test, upload reviews_Patio_Lawn_and_Garden_5.json.zip in this directory to your S3 bucket. To see if the lambda function is triggered, you can go to the Monitor tab.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f3451a-bbfc-4237-8b70-65105d8ff7cb",
   "metadata": {},
   "source": [
    "## Lambda Handler Starter Code: Parsing S3 Upload Event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b46278-f17c-4f49-b34c-23f3c1cb12bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: write a lambda_handler function here.\n",
    "# The code to parse S3 event has provided to you, you only need to call the `preprocess` from the HelloBlazePreprocessLambda.py and return the status.\n",
    "import json\n",
    "import urllib\n",
    "\n",
    "for r in event['Records']:\n",
    "        bucket = r['s3']['bucket']['name']\n",
    "        key = urllib.parse.unquote_plus(r['s3']['object']['key'], encoding='utf-8')\n",
    "        uri = \"/\".join([bucket, key])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13168a27-f2e5-4e9e-b045-7296904a89d7",
   "metadata": {},
   "source": [
    "## Triggering from CLI\n",
    "\n",
    "Below is a valid CLI function that will invoke a lambda function.\n",
    "\n",
    "aws lambda invoke --function-name preprocess-helloblze --payload '{\"s3-dataset-uri\": \"udacity-sagemaker-solutiondata2021/l3e1/reviews_Musical_Instruments_5.json.zip\"}' response.json\n",
    "\n",
    "Let's break this command down:\n",
    "\n",
    "aws lambda is the service we’re using.\n",
    "\n",
    "--function-name is the name of the function we're invoking.\n",
    "\n",
    "--payload is the payload we want to send to the function.\n",
    "\n",
    "response.json is where we want the output of this function to be written to.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc8c03a-9943-4a0e-9880-6bf711adafeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "692de0f1-84a6-44a9-9c17-ebe3c376df52",
   "metadata": {},
   "source": [
    "## Triggering from an S3 Upload.\n",
    "\n",
    "We will need to perform the following steps before modifying our lambda code:\n",
    "\n",
    "Create a new s3 folder within an existing bucket.\n",
    "Create a new lambda trigger for S3, specifying the bucket, specify the folder using the prefix, and specify a suffix of \".zip\" to ensure that recursive calls don't occur.\n",
    "We then need to modify the lambda handler starter code so that it properly parses the event that's sent to it.\n",
    "\n",
    "To test, we'll upload reviews_Patio_Lawn_and_Garden_5.json.zip in this directory to your S3 bucket. To see if the lambda function is triggered, you can go to the Monitor tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d653f3d-9c42-4dd8-a737-aef6db924365",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code\n",
    "\n",
    "import json\n",
    "import urllib\n",
    "from HelloBlazePreprocessLambda import preprocess\n",
    "\n",
    "def lambda_handler(event, context):\n",
    "    for r in event['Records']:\n",
    "        bucket = r['s3']['bucket']['name']\n",
    "        key = urllib.parse.unquote_plus(r['s3']['object']['key'], encoding='utf-8')\n",
    "        uri = \"/\".join([bucket, key])\n",
    "        preprocess(uri)\n",
    "    return {\n",
    "        'statusCode': 200,\n",
    "        'body': \"Good to go!\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5a41de-565f-4bcd-bd4f-174f5b76b61d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "989a1bff-07d4-4665-b2e1-e74d47f5f568",
   "metadata": {},
   "source": [
    "## Creating Workflows with Step Functions Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0abb96-07e0-4841-a588-04cc2ef4e89a",
   "metadata": {},
   "source": [
    "## SDK\n",
    "\n",
    "We then created a state machine in Boto3, using a state machine definition that we took from the UI. We made sure our SageMaker execution role had full access both to StepFunctions and Lambda.\n",
    "\n",
    "We used an IAM role that had access to Lambda, and with that invoked the create_state_machine function. Once that’s done, you can print the response to see the 200 ‘success’ code. Remember both that state-machine names and job names need to be unique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a384056f-5d8c-445b-a99e-83337c97a469",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.create_state_machine(\n",
    "    name='boto3StateMachine3', # Names need to be unique. \n",
    "    definition=definition,\n",
    "    roleArn='arn:aws:iam::565094796913:role/service-role/StepFunctions-firstStateMachine-role-0826984a',\n",
    "    type='STANDARD',\n",
    "    loggingConfiguration={\n",
    "        'level': 'OFF'\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ad5e2b-1fc1-419e-a502-c3324d7dbb9f",
   "metadata": {},
   "source": [
    "Once that was done, we executed this state machine by specifying an execution name, the URI of the state machine, and an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c510092-9e0c-4777-9d5f-324f2508a8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = client.start_execution(\n",
    "    stateMachineArn='arn:aws:states:us-west-2:565094796913:stateMachine:boto3StateMachine3', # You can find this through the Console or through the 'response' object. \n",
    "    name='example1', # Execution names need to be unique within state machines. \n",
    "    input='{}' # Input needs to be at least empty brackets. \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e296d3-6304-4f8b-a25d-6120186e486f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "237c32df-d5bb-439a-98b1-327cb012d5d8",
   "metadata": {},
   "source": [
    "## UDACITY Designing Your First Workflow - Step Functions\n",
    "\n",
    "#### Step Functions & SageMaker\n",
    "\n",
    "In the prior exercises, we've been working with many small services. This can be overwhelming for a data scientist that wants to establish a consistent methodology for handling data. Step Functions is an orchestration service that can allow us to utilize SageMaker in a methodical and consistent way. Step Functions also integrates with Lambda, which can allow us to potentially automate our entire machine learning pipeline end-to-end. Let's get a handle on what a 'step' in a step function looks like.\n",
    "\n",
    "In this exercise, you will create a preprocessing step and a training step. Then you will create a step function to chain the two steps.\n",
    "\n",
    "#### Exercise: Grant Permissions and install packages.\n",
    "\n",
    "\n",
    "Attach the IAMFullAccess and the StepFunctionsFullAccess polices to your SageMaker execution role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f7d3686-dfdc-4bb1-8d43-7bd5b51c464c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "pip install stepfunctions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dcada7-72ae-45bf-80a3-27a0f65dcfff",
   "metadata": {},
   "source": [
    "### Exercise: Fill out preprocessing step.\n",
    "\n",
    "The 'step' interface is designed to be quite similar to the Preprocessing Job in lesson 2. The main difference between these is the ability of a 'step' to interface with other steps. Given the successful outcome of a single step, the next step specified in a workflow will automatically continue. In our case, a training step will launch given the successful outcome of a preprocessing step. The preprocessing step has been encoded for you. Upload the preprocessing code 'HelloBlazePreprocess.py' and the zipped dataset 'reviews_Musical_Instruments_5.json.zip' to s3, and fill out the constants in the code below.\n",
    "\n",
    "Code below is the preprocessing step. Fill in the constants in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a44ddc-b1b4-4a71-b703-0c3407ceb625",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import get_execution_role\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from stepfunctions.steps.sagemaker import ProcessingStep\n",
    "import sagemaker\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "PREPROCESSING_JOB_NAME = \"preprocess-job\"\n",
    "input_data = 's3://mldeployex/reviews_Musical_Instruments_5.json.zip'\n",
    "input_preprocessing_code = 's3://mldeployex/HelloBlazePreprocess.py'\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type='ml.m5.large',\n",
    "                                     instance_count=1)\n",
    "\n",
    "\n",
    "processed_data_train = \"{}{}/{}\".format(\"s3://\", sess.default_bucket(), 'hello_blaze_train_scikit')\n",
    "processed_data_test = \"{}{}/{}\".format(\"s3://\", sess.default_bucket(), 'hello_blaze_test_scikit')\n",
    "\n",
    "inputs=[ProcessingInput(source=input_data, destination='/opt/ml/processing/input', input_name = 'input-1'),  ProcessingInput(source=input_preprocessing_code , destination='/opt/ml/processing/input/code', input_name = 'code')]\n",
    "\n",
    "\n",
    "outputs=[ProcessingOutput(source='/opt/ml/processing/output/train', destination=processed_data_train, output_name = 'train_data'), ProcessingOutput(source='/opt/ml/processing/output/test', destination=processed_data_test, output_name = 'test_data')]\n",
    "\n",
    "\n",
    "processing_step = ProcessingStep(\n",
    "    \"SageMaker pre-processing step 4\",\n",
    "    processor=sklearn_processor,\n",
    "    job_name=PREPROCESSING_JOB_NAME,\n",
    "    inputs=inputs,\n",
    "    outputs=outputs,\n",
    "    container_entrypoint=[\"python3\", \"/opt/ml/processing/input/code/HelloBlazePreprocess.py\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94aa4d2e-6fec-42df-9519-6d1d99aefa23",
   "metadata": {},
   "source": [
    "### Exercise: Fill out Training Step\n",
    "\n",
    "Upon the success of the preprocessing step, we wish to execute a training step. A training step is defined below. Fill the constants in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "378010e4-cdc9-48ce-a7b9-e93d5cbe921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stepfunctions.steps.sagemaker import TrainingStep\n",
    "import boto3\n",
    "\n",
    "WORKFLOW_OUTPUT = \"s3://udacity-sagemaker-solutiondata2021/l3e3/workflow_output\"\n",
    "TRAINING_JOB_NAME = \"test-job2-train\"\n",
    "\n",
    "region_name = boto3.Session().region_name\n",
    "container = sagemaker.image_uris.retrieve(\n",
    "    region=region_name, framework=\"blazingtext\", version=\"latest\"\n",
    ")\n",
    "\n",
    "helloBlazeEstimator = sagemaker.estimator.Estimator(\n",
    "    container,\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type='ml.m5.large',\n",
    "    volume_size=30,\n",
    "    max_run=360000,\n",
    "    input_mode=\"File\",\n",
    "    output_path=WORKFLOW_OUTPUT,\n",
    "    sagemaker_session=sess,\n",
    ")\n",
    "\n",
    "helloBlazeEstimator.set_hyperparameters(mode='supervised')\n",
    "\n",
    "training_step = TrainingStep(\n",
    "    \"SageMaker Training Step\",\n",
    "    estimator=helloBlazeEstimator,\n",
    "    data={\"train\": sagemaker.TrainingInput(processed_data_train, content_type=\"text/plain\"), \"validation\": sagemaker.TrainingInput(processed_data_test, content_type=\"text/plain\")},\n",
    "    job_name=TRAINING_JOB_NAME,\n",
    "    wait_for_completion=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe8f6d0-5545-4f68-bdf9-4ee0aff9eb7f",
   "metadata": {},
   "source": [
    "### Exercise: Create & Execute Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef3f89d-3b64-41fd-906f-d21c0841242c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stepfunctions.steps import Chain\n",
    "from stepfunctions.workflow import Workflow\n",
    "\n",
    "workflow_role = 'arn:aws:iam::354406515641:role/StepFunctionsLambdaRole'\n",
    "\n",
    "workflow_graph = Chain([processing_step, training_step])\n",
    "workflow = Workflow(\n",
    "    name=\"SageMakerProcessingWorkflow7\",\n",
    "    definition=workflow_graph,\n",
    "    role=workflow_role,\n",
    ")\n",
    "\n",
    "workflow.create()\n",
    "\n",
    "# Execute workflow\n",
    "execution = workflow.execute(\n",
    "    inputs={\n",
    "        \"PreprocessingJobName\": PREPROCESSING_JOB_NAME,  # Each pre processing job (SageMaker processing job) requires a unique name,\n",
    "        \"TrainingJobName\": TRAINING_JOB_NAME  # Each Sagemaker Training job requires a unique name,       \n",
    "    }\n",
    ")\n",
    "\n",
    "execution_output = execution.get_output(wait=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b302927a-0578-4c6f-8b7e-b65708b65107",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution.render_progress()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2bf3397-f65d-437b-9543-289e37be3473",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
